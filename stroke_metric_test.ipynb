{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ea27826",
   "metadata": {},
   "source": [
    "Test for stroke count and stroke rate\n",
    "\n",
    "1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b06e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0988edb031984aef81a08f1eb142ad82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='DB file path:', layout=Layout(width='80%'), placeholder='C:/path/to/your/database.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df07c355a6144e78698fdc2f429bfb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Load DB', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930b56e3e84f460c926414e1ffde1105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceecdc9b1dc14084bc80dc227c8341dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='CSV file path:', layout=Layout(width='80%'), placeholder='C:/path/to/your/stroke_d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7944574074044c90957e2cf8b22054d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Load CSV', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98418366c6248ae96b5ab46b27d2af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks, butter, filtfilt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from pathlib import Path\n",
    "\n",
    "if 'df' not in globals():\n",
    "    df = pd.DataFrame()\n",
    "if 'csv_df' not in globals():\n",
    "    csv_df = pd.DataFrame()\n",
    "\n",
    "db_file_input = widgets.Text(\n",
    "    value=\"\",\n",
    "    placeholder=\"C:/path/to/your/database.db\",\n",
    "    description='DB file path:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "load_db_button = widgets.Button(description=\"Load DB\", button_style='primary')\n",
    "db_load_output = widgets.Output()\n",
    "\n",
    "csv_file_input = widgets.Text(\n",
    "    value=\"\",\n",
    "    placeholder=\"C:/path/to/your/stroke_data.csv\",\n",
    "    description='CSV file path:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "load_csv_button = widgets.Button(description=\"Load CSV\", button_style='info')\n",
    "csv_load_output = widgets.Output()\n",
    "\n",
    "def load_db(_):\n",
    "    with db_load_output:\n",
    "        clear_output()\n",
    "        db_path = Path(db_file_input.value)\n",
    "        if not db_path.exists():\n",
    "            print(f\"Path not found: {db_path}\")\n",
    "            return\n",
    "        try:\n",
    "            conn = sqlite3.connect(str(db_path))\n",
    "            print(\"Available tables:\")\n",
    "            tables = pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
    "            display(tables)\n",
    "\n",
    "            table_name = 'sensor_data'\n",
    "            if table_name in tables['name'].values:\n",
    "                global df\n",
    "                df = pd.read_sql(f\"SELECT * FROM {table_name};\", conn)\n",
    "\n",
    "                # UNIX to ISO\n",
    "                if \"unix_ts\" in df.columns:\n",
    "                    df['datetime'] = (\n",
    "                        pd.to_datetime(df['unix_ts'], unit='ms', utc=True)\n",
    "                          .dt.tz_convert('Asia/Manila')\n",
    "                    )\n",
    "                elif \"timestamp\" in df.columns:\n",
    "                    df['datetime'] = (\n",
    "                        pd.to_datetime(df['timestamp'], unit='ms', utc=True)\n",
    "                          .dt.tz_convert('Asia/Manila')\n",
    "                    )\n",
    "                else:\n",
    "                    print(f\"Neither 'unix_ts' nor 'timestamp' column found in '{table_name}'. Cannot create 'datetime' column.\")\n",
    "                    return\n",
    "\n",
    "                print(f\"\\nPreview of '{table_name}':\")\n",
    "                display(df.head(5))\n",
    "\n",
    "                print(\"Columns:\")\n",
    "                print(df.columns.tolist())\n",
    "\n",
    "                if 'datetime' in df.columns:\n",
    "                    print(\"\\nTime range in dataset (Asia/Manila):\")\n",
    "                    print(df['datetime'].min(), \"to\", df['datetime'].max())\n",
    "            else:\n",
    "                print(f\"Table '{table_name}' not found in database.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to open DB: {e}\")\n",
    "\n",
    "load_db_button.on_click(load_db)\n",
    "\n",
    "def load_csv(_):\n",
    "    with csv_load_output:\n",
    "        clear_output()\n",
    "        csv_path = Path(csv_file_input.value)\n",
    "        if not csv_path.exists():\n",
    "            print(f\"Path not found: {csv_path}\")\n",
    "            return\n",
    "        try:\n",
    "            global csv_df\n",
    "            csv_df = pd.read_csv(csv_path)\n",
    "\n",
    "            if \"unix_ts\" in csv_df.columns:\n",
    "                csv_df['datetime'] = (\n",
    "                    pd.to_datetime(csv_df['unix_ts'], unit='ms', utc=True)\n",
    "                      .dt.tz_convert('Asia/Manila')\n",
    "                )\n",
    "\n",
    "            print(f\"\\nPreview of '{csv_path.name}':\")\n",
    "            display(csv_df.head(5))\n",
    "\n",
    "            print(\"Columns:\")\n",
    "            print(csv_df.columns.tolist())\n",
    "\n",
    "            if 'datetime' in csv_df.columns:\n",
    "                print(\"\\nTime range in CSV dataset (Asia/Manila):\")\n",
    "                print(csv_df['datetime'].min(), \"to\", csv_df['datetime'].max())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load CSV: {e}\")\n",
    "\n",
    "load_csv_button.on_click(load_csv)\n",
    "\n",
    "display(db_file_input, load_db_button, db_load_output,\n",
    "        csv_file_input, load_csv_button, csv_load_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d61b9a",
   "metadata": {},
   "source": [
    "2. Butterworth filter\n",
    "\n",
    "References:\n",
    "https://doi.org/10.1016/j.proeng.2010.04.055\n",
    "\n",
    "http://dx.doi.org/10.4236/jsip.2012.34062"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec58bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass_filter(data, lowcut=0.25, highcut=0.5, fs=50, order=2):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return filtfilt(b, a, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a80512",
   "metadata": {},
   "source": [
    "3. Sampling rate estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dc852dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_sampling_rate(df):\n",
    "    diffs = df['datetime'].diff().dt.total_seconds().dropna()\n",
    "    return 1.0 / diffs.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb9d917",
   "metadata": {},
   "source": [
    "4. Stroke cycle identification (Peak detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e645fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_stroke_cycles(segment):\n",
    "    if not all(col in segment.columns for col in ['accel_y', 'accel_z']):\n",
    "        print(\"⚠️ accel_y and accel_z not found.\")\n",
    "        return 0, [], []\n",
    "\n",
    "    fs = estimate_sampling_rate(segment)\n",
    "    ay_f = butter_bandpass_filter(segment['accel_y'].values, fs=fs)\n",
    "    az_f = butter_bandpass_filter(segment['accel_z'].values, fs=fs)\n",
    "    signal = ay_f + az_f\n",
    "\n",
    "    peaks, _ = find_peaks(signal)\n",
    "    valid_peaks = list(peaks)\n",
    "\n",
    "    return len(valid_peaks), valid_peaks, signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaa3db4",
   "metadata": {},
   "source": [
    "5. Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba23b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ceb1fa1cf5e4c94a13f7678ca5c6be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Data Source:', options=(('Database (Accelerometer)', 'db'), ('CSV (Annotated Strokes)', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87bfb347706424b840cb32f1a8ff7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='07:00:00', description='Start Time (HH:MM:SS GMT+8):', layout=Layout(width='90%'), style=TextStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8ac6f67f3749b482bf73d7207def27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='07:05:00', description='End Time (HH:MM:SS GMT+8):', layout=Layout(width='90%'), style=TextStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2f4d5e3b964ccf8cbd3feadd3dad9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Calculate Stroke Metrics', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539c05dbfbd2426398cc0b39e43bd2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# inputs\n",
    "data_source_select = widgets.Dropdown(\n",
    "    options=[('Database (Accelerometer)', 'db'), ('CSV (Annotated Strokes)', 'csv')],\n",
    "    value='db',\n",
    "    description='Data Source:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "start_time_input = widgets.Text(\n",
    "    value=\"07:00:00\",\n",
    "    description='Start Time (HH:MM:SS GMT+8):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "end_time_input = widgets.Text(\n",
    "    value=\"07:05:00\",\n",
    "    description='End Time (HH:MM:SS GMT+8):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def calculate_stroke_metrics(change):\n",
    "    with output:\n",
    "        clear_output()\n",
    "\n",
    "        source = data_source_select.value\n",
    "        current_df = None\n",
    "        if source == 'db':\n",
    "            if 'df' not in globals() or df.empty:\n",
    "                print(\"DB data not loaded. Please load the .db file first.\")\n",
    "                return\n",
    "            current_df = df\n",
    "        elif source == 'csv':\n",
    "            if 'csv_df' not in globals() or csv_df.empty:\n",
    "                print(\"CSV data not loaded. Please load the .csv file first.\")\n",
    "                return\n",
    "            current_df = csv_df\n",
    "        \n",
    "        if 'datetime' not in current_df.columns:\n",
    "            print(\"Error: 'datetime' column not found in the selected data. Please ensure the data is loaded correctly with a 'timestamp' or 'unix_ts' column.\")\n",
    "            return\n",
    "        \n",
    "        if current_df['datetime'].empty:\n",
    "            print(\"Error: 'datetime' column is empty. No time data available for analysis.\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\nFull data time range (GMT+8): {current_df['datetime'].min().strftime('%Y-%m-%d %H:%M:%S')} to {current_df['datetime'].max().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "        try:\n",
    "            start_time_str = start_time_input.value\n",
    "            end_time_str = end_time_input.value\n",
    "\n",
    "            base_date = current_df['datetime'].iloc[0].date()\n",
    "            \n",
    "            start_time = pd.to_datetime(f\"{base_date} {start_time_str}\").tz_localize('Asia/Manila')\n",
    "            end_time = pd.to_datetime(f\"{base_date} {end_time_str}\").tz_localize('Asia/Manila')\n",
    "\n",
    "            print(f\"Filtering for: {start_time.strftime('%Y-%m-%d %H:%M:%S')} GMT+8 to {end_time.strftime('%Y-%m-%d %H:%M:%S')} GMT+8\")\n",
    "\n",
    "        except ValueError:\n",
    "            print(\"Invalid time format. Please use HH:MM:SS.\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing times: {e}\")\n",
    "            return\n",
    "\n",
    "        mask = (current_df['datetime'] >= start_time) & (current_df['datetime'] <= end_time)\n",
    "        segment = current_df[mask]\n",
    "\n",
    "        if segment.empty:\n",
    "            print(\"No data in selected time range.\")\n",
    "            return\n",
    "\n",
    "        if source == 'db':\n",
    "            # stroke cycle identification for DB data\n",
    "            stroke_count, peaks, signal = identify_stroke_cycles(segment)\n",
    "            print(f\"Detected Stroke Count (DB): {stroke_count}\")\n",
    "\n",
    "            # calculate stroke rate\n",
    "            duration_seconds = (end_time - start_time).total_seconds()\n",
    "            stroke_rate = (stroke_count / duration_seconds) * 60 if duration_seconds > 0 else 0\n",
    "            print(f\"Stroke Rate (DB): {stroke_rate:.2f} strokes/min\")\n",
    "\n",
    "            # results plot\n",
    "            plt.figure(figsize=(12,4))\n",
    "            plt.plot(segment['datetime'], signal, label=\"Filtered ay+az\")\n",
    "            if len(peaks) > 0:\n",
    "                plt.plot(segment['datetime'].iloc[peaks], signal[peaks], \"rx\", label=\"Strokes\")\n",
    "            plt.xlabel(\"Time\")\n",
    "            plt.ylabel(\"Filtered Acceleration (m/s^2)\")\n",
    "            plt.legend()\n",
    "            plt.title(f\"Stroke Analysis (DB Data) from {start_time.strftime('%H:%M:%S')} to {end_time.strftime('%H:%M:%S')}\")\n",
    "            plt.show()\n",
    "        elif source == 'csv':\n",
    "            # stroke count\n",
    "            stroke_count = segment.shape[0]\n",
    "            print(f\"Annotated Stroke Count (CSV): {stroke_count}\")\n",
    "\n",
    "            # calculate stroke rate\n",
    "            duration_seconds = (end_time - start_time).total_seconds()\n",
    "            stroke_rate = (stroke_count / duration_seconds) * 60 if duration_seconds > 0 else 0\n",
    "            print(f\"Stroke Rate (CSV): {stroke_rate:.2f} strokes/min\")\n",
    "\n",
    "calc_button = widgets.Button(\n",
    "    description=\"Calculate Stroke Metrics\",\n",
    "    button_style='success'\n",
    ")\n",
    "\n",
    "calc_button.on_click(None)\n",
    "calc_button.on_click(calculate_stroke_metrics)\n",
    "\n",
    "display(data_source_select, start_time_input, end_time_input, calc_button, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b828a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2182b47e5d84447c8e53f4fd6d449775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='Compare Data', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b65720f8cf4a52bed3c481ac03c31d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_all_button = widgets.Button(\n",
    "    description=\"Compare Data\",\n",
    "    button_style='warning'\n",
    ")\n",
    "compare_output = widgets.Output()\n",
    "\n",
    "def compare_all_data(_):\n",
    "    with compare_output:\n",
    "        clear_output()\n",
    "        if 'csv_df' not in globals() or csv_df.empty:\n",
    "            print(\"CSV data not loaded. Please load the .csv file first.\")\n",
    "            return\n",
    "        if 'df' not in globals() or df.empty:\n",
    "            print(\"DB data not loaded. Please load the .db file first.\")\n",
    "            return\n",
    "        if 'datetime' not in csv_df.columns or 'datetime' not in df.columns:\n",
    "            print(\"Error: 'datetime' column not found in one or both data sources.\")\n",
    "            return\n",
    "\n",
    "        if 'unix_ts' in csv_df.columns:\n",
    "            start_unix = csv_df['unix_ts'].iloc[0]\n",
    "            end_unix = csv_df['unix_ts'].iloc[-1]\n",
    "        elif 'timestamp' in csv_df.columns:\n",
    "            start_unix = csv_df['timestamp'].iloc[0]\n",
    "            end_unix = csv_df['timestamp'].iloc[-1]\n",
    "        else:\n",
    "            print(\"CSV does not have 'unix_ts' or 'timestamp' column.\")\n",
    "            return\n",
    "        start_dt = pd.to_datetime(start_unix, unit='ms', utc=True).tz_convert('Asia/Manila')\n",
    "        end_dt = pd.to_datetime(end_unix, unit='ms', utc=True).tz_convert('Asia/Manila')\n",
    "        print(f\"Comparing over time range: {start_dt} to {end_dt}\")\n",
    "\n",
    "        csv_stroke_count = csv_df.shape[0]\n",
    "        print(f\"\\nAnnotated Stroke Count: {csv_stroke_count}\")\n",
    "\n",
    "        db_segment = df[(df['datetime'] >= start_dt) & (df['datetime'] <= end_dt)]\n",
    "        if db_segment.empty:\n",
    "            print(\"No DB data in this time range.\")\n",
    "            db_stroke_count = 0\n",
    "        else:\n",
    "            db_stroke_count, _, _ = identify_stroke_cycles(db_segment)\n",
    "        print(f\"Stroke Count (peak detection): {db_stroke_count}\")\n",
    "\n",
    "compare_all_button.on_click(compare_all_data)\n",
    "\n",
    "display(compare_all_button, compare_output)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
