{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ea27826",
   "metadata": {},
   "source": [
    "Test for stroke count and stroke rate\n",
    "\n",
    "1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b06e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde0feb981fe4b188c05c33ddf3a10f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='DB file path:', layout=Layout(width='80%'), placeholder='C:/path/to/your/database.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c514b8b06f44cbbdb0642618dd00d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Load DB', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6169d660734ff7a6c3730d533fcf3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac57947fc8774d9398e2726fdc6ca9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='CSV file path:', layout=Layout(width='80%'), placeholder='C:/path/to/your/stroke_d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab00e30fbf4347adb13a12a88ecbb13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Load CSV', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19cb1aa884164d28b7d9f6d5bc931674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks, butter, filtfilt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from pathlib import Path\n",
    "\n",
    "if 'df' not in globals():\n",
    "    df = pd.DataFrame()\n",
    "if 'csv_df' not in globals():\n",
    "    csv_df = pd.DataFrame()\n",
    "\n",
    "db_file_input = widgets.Text(\n",
    "    value=\"\",\n",
    "    placeholder=\"C:/path/to/your/database.db\",\n",
    "    description='DB file path:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "load_db_button = widgets.Button(description=\"Load DB\", button_style='primary')\n",
    "db_load_output = widgets.Output()\n",
    "\n",
    "csv_file_input = widgets.Text(\n",
    "    value=\"\",\n",
    "    placeholder=\"C:/path/to/your/stroke_data.csv\",\n",
    "    description='CSV file path:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "load_csv_button = widgets.Button(description=\"Load CSV\", button_style='info')\n",
    "csv_load_output = widgets.Output()\n",
    "\n",
    "def load_db(_):\n",
    "    with db_load_output:\n",
    "        clear_output()\n",
    "        db_path = Path(db_file_input.value)\n",
    "        if not db_path.exists():\n",
    "            print(f\"Path not found: {db_path}\")\n",
    "            return\n",
    "        try:\n",
    "            conn = sqlite3.connect(str(db_path))\n",
    "            print(\"Available tables:\")\n",
    "            tables = pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
    "            display(tables)\n",
    "\n",
    "            table_name = 'sensor_data'\n",
    "            if table_name in tables['name'].values:\n",
    "                global df\n",
    "                df = pd.read_sql(f\"SELECT * FROM {table_name};\", conn)\n",
    "\n",
    "                # UNIX to ISO\n",
    "                if \"unix_ts\" in df.columns:\n",
    "                    df['datetime'] = (\n",
    "                        pd.to_datetime(df['unix_ts'], unit='ms', utc=True)\n",
    "                          .dt.tz_convert('Asia/Manila')\n",
    "                    )\n",
    "                elif \"timestamp\" in df.columns:\n",
    "                    df['datetime'] = (\n",
    "                        pd.to_datetime(df['timestamp'], unit='ms', utc=True)\n",
    "                          .dt.tz_convert('Asia/Manila')\n",
    "                    )\n",
    "                else:\n",
    "                    print(f\"Neither 'unix_ts' nor 'timestamp' column found in '{table_name}'. Cannot create 'datetime' column.\")\n",
    "                    return\n",
    "\n",
    "                print(f\"\\nPreview of '{table_name}':\")\n",
    "                display(df.head(5))\n",
    "\n",
    "                print(\"Columns:\")\n",
    "                print(df.columns.tolist())\n",
    "\n",
    "                if 'datetime' in df.columns:\n",
    "                    print(\"\\nTime range in dataset (Asia/Manila):\")\n",
    "                    print(df['datetime'].min(), \"to\", df['datetime'].max())\n",
    "            else:\n",
    "                print(f\"Table '{table_name}' not found in database.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to open DB: {e}\")\n",
    "\n",
    "load_db_button.on_click(load_db)\n",
    "\n",
    "def load_csv(_):\n",
    "    with csv_load_output:\n",
    "        clear_output()\n",
    "        csv_path = Path(csv_file_input.value)\n",
    "        if not csv_path.exists():\n",
    "            print(f\"Path not found: {csv_path}\")\n",
    "            return\n",
    "        try:\n",
    "            global csv_df\n",
    "            csv_df = pd.read_csv(csv_path)\n",
    "\n",
    "            if \"unix_ts\" in csv_df.columns:\n",
    "                csv_df['datetime'] = (\n",
    "                    pd.to_datetime(csv_df['unix_ts'], unit='ms', utc=True)\n",
    "                      .dt.tz_convert('Asia/Manila')\n",
    "                )\n",
    "\n",
    "            print(f\"\\nPreview of '{csv_path.name}':\")\n",
    "            display(csv_df.head(30))\n",
    "\n",
    "            print(\"Columns:\")\n",
    "            print(csv_df.columns.tolist())\n",
    "\n",
    "            if 'datetime' in csv_df.columns:\n",
    "                print(\"\\nTime range in CSV dataset (Asia/Manila):\")\n",
    "                print(csv_df['datetime'].min(), \"to\", csv_df['datetime'].max())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load CSV: {e}\")\n",
    "\n",
    "load_csv_button.on_click(load_csv)\n",
    "\n",
    "display(db_file_input, load_db_button, db_load_output,\n",
    "        csv_file_input, load_csv_button, csv_load_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d61b9a",
   "metadata": {},
   "source": [
    "2. Butterworth filter\n",
    "\n",
    "References:\n",
    "https://doi.org/10.1016/j.proeng.2010.04.055\n",
    "\n",
    "http://dx.doi.org/10.4236/jsip.2012.34062"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec58bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass_filter(data, lowcut=0.25, highcut=0.5, fs=50, order=2):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return filtfilt(b, a, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a80512",
   "metadata": {},
   "source": [
    "3. Sampling rate estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dc852dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_sampling_rate(df):\n",
    "    diffs = df['datetime'].diff().dt.total_seconds().dropna()\n",
    "    return 1.0 / diffs.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb9d917",
   "metadata": {},
   "source": [
    "4. Stroke cycle identification (Peak detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e645fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_stroke_cycles(segment):\n",
    "    if not all(col in segment.columns for col in ['accel_y', 'accel_z']):\n",
    "        print(\"accel_y and accel_z not found.\")\n",
    "        return 0, [], []\n",
    "\n",
    "    fs = estimate_sampling_rate(segment)\n",
    "    ay_f = butter_bandpass_filter(segment['accel_y'].values, fs=fs)\n",
    "    az_f = butter_bandpass_filter(segment['accel_z'].values, fs=fs)\n",
    "    signal = ay_f + az_f\n",
    "\n",
    "    peaks, _ = find_peaks(signal)\n",
    "    valid_peaks = list(peaks)\n",
    "\n",
    "    return len(valid_peaks), valid_peaks, signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaa3db4",
   "metadata": {},
   "source": [
    "5. Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ba23b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a7302db6c74842b78263713a220172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Data Source:', options=(('Database (Accelerometer)', 'db'), ('CSV (Annotated Strokes)', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9825aca55e064be8aad9c61bc071e26a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='07:00:00', description='Start Time (HH:MM:SS GMT+8):', layout=Layout(width='90%'), style=TextStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5d3817c3c9425b9ea015226a76819b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='07:05:00', description='End Time (HH:MM:SS GMT+8):', layout=Layout(width='90%'), style=TextStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44d2ddb166e4b5babb5d9ba64ce8f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Calculate Stroke Metrics', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15cbb91f4e246d29ae2f0f912adb210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# inputs\n",
    "data_source_select = widgets.Dropdown(\n",
    "    options=[('Database (Accelerometer)', 'db'), ('CSV (Annotated Strokes)', 'csv')],\n",
    "    value='db',\n",
    "    description='Data Source:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "start_time_input = widgets.Text(\n",
    "    value=\"07:00:00\",\n",
    "    description='Start Time (HH:MM:SS GMT+8):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "end_time_input = widgets.Text(\n",
    "    value=\"07:05:00\",\n",
    "    description='End Time (HH:MM:SS GMT+8):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def calculate_stroke_metrics(change):\n",
    "    with output:\n",
    "        clear_output()\n",
    "\n",
    "        source = data_source_select.value\n",
    "        current_df = None\n",
    "        if source == 'db':\n",
    "            if 'df' not in globals() or df.empty:\n",
    "                print(\"DB data not loaded. Please load the .db file first.\")\n",
    "                return\n",
    "            current_df = df\n",
    "        elif source == 'csv':\n",
    "            if 'csv_df' not in globals() or csv_df.empty:\n",
    "                print(\"CSV data not loaded. Please load the .csv file first.\")\n",
    "                return\n",
    "            current_df = csv_df\n",
    "        \n",
    "        if 'datetime' not in current_df.columns:\n",
    "            print(\"Error: 'datetime' column not found in the selected data. Please ensure the data is loaded correctly with a 'timestamp' or 'unix_ts' column.\")\n",
    "            return\n",
    "        \n",
    "        if current_df['datetime'].empty:\n",
    "            print(\"Error: 'datetime' column is empty. No time data available for analysis.\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\nFull data time range (GMT+8): {current_df['datetime'].min().strftime('%Y-%m-%d %H:%M:%S')} to {current_df['datetime'].max().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "        try:\n",
    "            start_time_str = start_time_input.value\n",
    "            end_time_str = end_time_input.value\n",
    "\n",
    "            base_date = current_df['datetime'].iloc[0].date()\n",
    "            \n",
    "            start_time = pd.to_datetime(f\"{base_date} {start_time_str}\").tz_localize('Asia/Manila')\n",
    "            end_time = pd.to_datetime(f\"{base_date} {end_time_str}\").tz_localize('Asia/Manila')\n",
    "\n",
    "            print(f\"Filtering for: {start_time.strftime('%Y-%m-%d %H:%M:%S')} GMT+8 to {end_time.strftime('%Y-%m-%d %H:%M:%S')} GMT+8\")\n",
    "\n",
    "        except ValueError:\n",
    "            print(\"Invalid time format. Please use HH:MM:SS.\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing times: {e}\")\n",
    "            return\n",
    "\n",
    "        mask = (current_df['datetime'] >= start_time) & (current_df['datetime'] <= end_time)\n",
    "        segment = current_df[mask]\n",
    "\n",
    "        if segment.empty:\n",
    "            print(\"No data in selected time range.\")\n",
    "            return\n",
    "\n",
    "        if source == 'db':\n",
    "            # stroke cycle identification for DB data\n",
    "            stroke_count, peaks, signal = identify_stroke_cycles(segment)\n",
    "            print(f\"Detected Stroke Count (DB): {stroke_count}\")\n",
    "\n",
    "            # calculate stroke rate\n",
    "            duration_seconds = (end_time - start_time).total_seconds()\n",
    "            stroke_rate = (stroke_count / duration_seconds) * 60 if duration_seconds > 0 else 0\n",
    "            print(f\"Stroke Rate (DB): {stroke_rate:.2f} strokes/min\")\n",
    "\n",
    "            # results plot\n",
    "            plt.figure(figsize=(12,4))\n",
    "            plt.plot(segment['datetime'], signal, label=\"Filtered ay+az\")\n",
    "            if len(peaks) > 0:\n",
    "                plt.plot(segment['datetime'].iloc[peaks], signal[peaks], \"rx\", label=\"Strokes\")\n",
    "            plt.xlabel(\"Time\")\n",
    "            plt.ylabel(\"Filtered Acceleration (m/s^2)\")\n",
    "            plt.legend()\n",
    "            plt.title(f\"Stroke Analysis (DB Data) from {start_time.strftime('%H:%M:%S')} to {end_time.strftime('%H:%M:%S')}\")\n",
    "            plt.show()\n",
    "        elif source == 'csv':\n",
    "            # stroke count\n",
    "            stroke_count = segment.shape[0]\n",
    "            print(f\"Annotated Stroke Count (CSV): {stroke_count}\")\n",
    "\n",
    "            # calculate stroke rate\n",
    "            duration_seconds = (end_time - start_time).total_seconds()\n",
    "            stroke_rate = (stroke_count / duration_seconds) * 60 if duration_seconds > 0 else 0\n",
    "            print(f\"Stroke Rate (CSV): {stroke_rate:.2f} strokes/min\")\n",
    "\n",
    "calc_button = widgets.Button(\n",
    "    description=\"Calculate Stroke Metrics\",\n",
    "    button_style='success'\n",
    ")\n",
    "\n",
    "# Register only the valid handler\n",
    "calc_button.on_click(calculate_stroke_metrics)\n",
    "\n",
    "display(data_source_select, start_time_input, end_time_input, calc_button, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef5dc5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9824aa89fd4f078f0a3de729051266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Export a time slice of the loaded DB</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8841a3a8db2d40619271b859683fc2ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Start (YYYY-MM-DD HH:MM:SS GMT+8):', layout=Layout(width='95%'), style=TextStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93ab087bc054403831dbb4bafcf123a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='End (YYYY-MM-DD HH:MM:SS GMT+8):', layout=Layout(width='95%'), style=TextStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1a217737b7414ab00d13b5aa6df9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='sliced_data.csv', description='CSV out path:', layout=Layout(width='80%'), style=Te…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be939e872ce44c5aa6f60d1770630a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='sliced_data.db', description='SQLite out path:', layout=Layout(width='80%'), style=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5438c5afa574eecba90d5f5fcdbcfa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "export_start_input = widgets.Text(\n",
    "    value=\"\",\n",
    "    description='Start (YYYY-MM-DD HH:MM:SS GMT+8):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='95%')\n",
    ")\n",
    "\n",
    "export_end_input = widgets.Text(\n",
    "    value=\"\",\n",
    "    description='End (YYYY-MM-DD HH:MM:SS GMT+8):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='95%')\n",
    ")\n",
    "\n",
    "export_csv_path_input = widgets.Text(\n",
    "    value=\"sliced_data.csv\",\n",
    "    description='CSV out path:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "export_db_path_input = widgets.Text(\n",
    "    value=\"sliced_data.db\",\n",
    "    description='SQLite out path:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "table_name_input = widgets.Text(\n",
    "    value=\"sensor_data\",\n",
    "    description='SQLite table:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "export_output = widgets.Output()\n",
    "\n",
    "export_csv_button = widgets.Button(\n",
    "    description=\"Export Slice to CSV\",\n",
    "    button_style='primary'\n",
    ")\n",
    "\n",
    "export_sqlite_button = widgets.Button(\n",
    "    description=\"Export Slice to SQLite\",\n",
    "    button_style='warning'\n",
    ")\n",
    "\n",
    "\n",
    "def _get_time_bounds(current_df):\n",
    "    start_raw = export_start_input.value.strip()\n",
    "    end_raw = export_end_input.value.strip()\n",
    "\n",
    "    if start_raw:\n",
    "        start_dt = pd.to_datetime(start_raw, errors='raise')\n",
    "        if start_dt.tzinfo is None:\n",
    "            start_dt = start_dt.tz_localize('Asia/Manila')\n",
    "        else:\n",
    "            start_dt = start_dt.tz_convert('Asia/Manila')\n",
    "    else:\n",
    "        start_dt = current_df['datetime'].min()\n",
    "\n",
    "    if end_raw:\n",
    "        end_dt = pd.to_datetime(end_raw, errors='raise')\n",
    "        if end_dt.tzinfo is None:\n",
    "            end_dt = end_dt.tz_localize('Asia/Manila')\n",
    "        else:\n",
    "            end_dt = end_dt.tz_convert('Asia/Manila')\n",
    "    else:\n",
    "        end_dt = current_df['datetime'].max()\n",
    "\n",
    "    return start_dt, end_dt\n",
    "\n",
    "\n",
    "def _slice_current_df():\n",
    "    if 'df' not in globals() or df.empty or 'datetime' not in df.columns:\n",
    "        return pd.DataFrame(), \"DB data not loaded or missing 'datetime'.\"\n",
    "    start_dt, end_dt = _get_time_bounds(df)\n",
    "    mask = (df['datetime'] >= start_dt) & (df['datetime'] <= end_dt)\n",
    "    segment = df[mask].copy()\n",
    "    if segment.empty:\n",
    "        return pd.DataFrame(), \"No data in selected time range.\"\n",
    "    return segment, f\"Slice rows: {len(segment)} | {start_dt} to {end_dt}\"\n",
    "\n",
    "\n",
    "def on_export_csv(_):\n",
    "    with export_output:\n",
    "        clear_output()\n",
    "        segment, msg = _slice_current_df()\n",
    "        if segment.empty:\n",
    "            print(msg)\n",
    "            return\n",
    "        out_path = export_csv_path_input.value.strip() or \"sliced_data.csv\"\n",
    "        # Drop helper columns not in original DB schema\n",
    "        to_save = segment.copy()\n",
    "        if 'datetime' in to_save.columns:\n",
    "            to_save = to_save.drop(columns=['datetime'])\n",
    "        to_save.to_csv(out_path, index=False)\n",
    "        print(f\"Saved CSV: {out_path}\")\n",
    "        print(msg)\n",
    "\n",
    "\n",
    "def on_export_sqlite(_):\n",
    "    with export_output:\n",
    "        clear_output()\n",
    "        segment, msg = _slice_current_df()\n",
    "        if segment.empty:\n",
    "            print(msg)\n",
    "            return\n",
    "        out_path = export_db_path_input.value.strip() or \"sliced_data.db\"\n",
    "        tbl = table_name_input.value.strip() or \"sensor_data\"\n",
    "        conn = None\n",
    "        try:\n",
    "            conn = sqlite3.connect(out_path)\n",
    "            to_save = segment.copy()\n",
    "            if 'datetime' in to_save.columns:\n",
    "                to_save = to_save.drop(columns=['datetime'])\n",
    "            to_save.to_sql(tbl, conn, if_exists='replace', index=False)\n",
    "            print(f\"Saved SQLite DB: {out_path} (table: {tbl})\")\n",
    "            print(msg)\n",
    "        except Exception as e:\n",
    "            print(f\"Export failed: {e}\")\n",
    "        finally:\n",
    "            if conn is not None:\n",
    "                conn.close()\n",
    "\n",
    "\n",
    "export_csv_button.on_click(on_export_csv)\n",
    "export_sqlite_button.on_click(on_export_sqlite)\n",
    "\n",
    "display(widgets.HTML(value=\"<h3>Export a time slice of the loaded DB</h3>\"))\n",
    "display(export_start_input, export_end_input)\n",
    "display(widgets.HBox([export_csv_path_input, export_csv_button]))\n",
    "display(widgets.HBox([export_db_path_input, table_name_input, export_sqlite_button]))\n",
    "display(export_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b828a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e85450d46bf4227abd3bb1aab7e8c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='Compare Data', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b18d6200dc407b80769cdfb0971148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_all_button = widgets.Button(\n",
    "    description=\"Compare Data\",\n",
    "    button_style='warning'\n",
    ")\n",
    "compare_output = widgets.Output()\n",
    "\n",
    "def compare_all_data(_):\n",
    "    with compare_output:\n",
    "        clear_output()\n",
    "        if 'csv_df' not in globals() or csv_df.empty:\n",
    "            print(\"CSV data not loaded. Please load the .csv file first.\")\n",
    "            return\n",
    "        if 'df' not in globals() or df.empty:\n",
    "            print(\"DB data not loaded. Please load the .db file first.\")\n",
    "            return\n",
    "        if 'datetime' not in csv_df.columns or 'datetime' not in df.columns:\n",
    "            print(\"Error: 'datetime' column not found in one or both data sources.\")\n",
    "            return\n",
    "\n",
    "        if 'unix_ts' in csv_df.columns:\n",
    "            start_unix = csv_df['unix_ts'].iloc[0]\n",
    "            end_unix = csv_df['unix_ts'].iloc[-1]\n",
    "        elif 'timestamp' in csv_df.columns:\n",
    "            start_unix = csv_df['timestamp'].iloc[0]\n",
    "            end_unix = csv_df['timestamp'].iloc[-1]\n",
    "        else:\n",
    "            print(\"CSV does not have 'unix_ts' or 'timestamp' column.\")\n",
    "            return\n",
    "        start_dt = pd.to_datetime(start_unix, unit='ms', utc=True).tz_convert('Asia/Manila')\n",
    "        end_dt = pd.to_datetime(end_unix, unit='ms', utc=True).tz_convert('Asia/Manila')\n",
    "        print(f\"Comparing over time range: {start_dt} to {end_dt}\")\n",
    "\n",
    "        csv_stroke_count = csv_df.shape[0]\n",
    "        print(f\"\\nAnnotated Stroke Count: {csv_stroke_count}\")\n",
    "\n",
    "        db_segment = df[(df['datetime'] >= start_dt) & (df['datetime'] <= end_dt)]\n",
    "        if db_segment.empty:\n",
    "            print(\"No DB data in this time range.\")\n",
    "            db_stroke_count = 0\n",
    "        else:\n",
    "            db_stroke_count, _, _ = identify_stroke_cycles(db_segment)\n",
    "        print(f\"Stroke Count (peak detection): {db_stroke_count}\")\n",
    "\n",
    "compare_all_button.on_click(compare_all_data)\n",
    "\n",
    "display(compare_all_button, compare_output)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
